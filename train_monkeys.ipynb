{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Squirrel Monkey Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets rid of a HOST of deprecation warnings for Matterport\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# and Tensorflow\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.model import log\n",
    "from mrcnn import visualize\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import utils\n",
    "from mrcnn.config import Config\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from termcolor import colored\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./Mask_RCNN\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# COCO_MODEL_PATH = \"C:\\\\Users\\\\addis\\\\Documents\\\\mask_rcnn_coco.h5\"\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check tf version\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "SEED = 123\n",
    "IOU_THRESHOLD = 0.9\n",
    "BATCH_SIZE = 8\n",
    "IMAGES_PER_GPU_CONFIG = BATCH_SIZE\n",
    "\n",
    "DATASET_DIR = Path(\"F:/Adam/Pictures/AucklandZooImages/cv set (240)\")\n",
    "\n",
    "num_folds = 3\n",
    "num_train_epochs = 5\n",
    "num_fine_tune_epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonkeysConfig(Config):\n",
    "    #################### BASE CONFIGURATION ####################\n",
    "    NAME = \"monkeys\"\n",
    "\n",
    "    # Train on 1 GPU\n",
    "    GPU_COUNT = 1\n",
    "    # batch size of 4\n",
    "    IMAGES_PER_GPU = IMAGES_PER_GPU_CONFIG\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 monkey\n",
    "    DETECTION_MAX_INSTANCES = 1  # we're only looking for the most prominent individual in each image\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # RPN ANCHOR SCALES left as default (32, 64, 128, 256, 512), in line with the FaterRCNN paper\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    IMAGE_SHAPE = np.array([256, 256, 3])\n",
    "\n",
    "    # (the number of batch iterations before a training epoch is considered finished). As we want to train on the full dataset, it's equal to num_samples/batch_size\n",
    "    # STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # VALIDATION_STEPS is similiar to STEPS_PER_EPOCH\n",
    "\n",
    "\n",
    "class InferenceConfig(MonkeysConfig):\n",
    "    GPU_COUNT = 1\n",
    "    # Batch size of 1 for inference\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "def get_config(learning_rate, num_samples):\n",
    "    # config used for both training and inference\n",
    "    train_config = MonkeysConfig()\n",
    "    inference_config = InferenceConfig()\n",
    "\n",
    "    for config in [train_config, inference_config]:\n",
    "        #################### HYPERPARAMETERS TO TUNE ####################\n",
    "        config.LEARNING_RATE = learning_rate\n",
    "\n",
    "        config.STEPS_PER_EPOCH = int(num_samples / config.BATCH_SIZE)\n",
    "\n",
    "    train_config.display()\n",
    "\n",
    "    return train_config, inference_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Handles loading images and masks for the custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "MONKEY_CLASS_ID_STR = \"monkey\"\n",
    "\n",
    "\n",
    "class MonkeysDataset(utils.Dataset):\n",
    "    def load_monkeys(self, dataset_dir, subset):\n",
    "\n",
    "        # Add classes\n",
    "        self.add_class(MONKEY_CLASS_ID_STR, 1, MONKEY_CLASS_ID_STR)\n",
    "\n",
    "        num_images_added = 0\n",
    "       # Load annotations\n",
    "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
    "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "        #   'regions': {\n",
    "        #       '0': {\n",
    "        #           'region_attributes': {},\n",
    "        #           'shape_attributes': {\n",
    "        #               'all_points_x': [...],\n",
    "        #               'all_points_y': [...],\n",
    "        #               'name': 'polygon'}},\n",
    "        #       ... more regions ...\n",
    "        #   },\n",
    "        #   'size': 100202\n",
    "        # }\n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
    "        annotations = json.load(\n",
    "            open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            if a['filename'] in subset:\n",
    "                # Get the x, y coordinaets of points of the polygons that make up\n",
    "                # the outline of each object instance. These are stores in the\n",
    "                # shape_attributes (see json format above)\n",
    "                # The if condition is needed to support VIA versions 1.x and 2.x.\n",
    "                if type(a['regions']) is dict:\n",
    "                    polygons = [r['shape_attributes']\n",
    "                                for r in a['regions'].values()]\n",
    "                else:\n",
    "                    polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "\n",
    "                # load_mask() needs the image size to convert polygons to masks.\n",
    "                # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "                # the image. This is only managable since the dataset is tiny.\n",
    "                image_path = os.path.join(dataset_dir, \"images\", a['filename'])\n",
    "                image = skimage.io.imread(image_path)\n",
    "                height, width = image.shape[:2]\n",
    "\n",
    "                self.add_image(\n",
    "                    MONKEY_CLASS_ID_STR,\n",
    "                    image_id=a['filename'],  # use file name as a unique image id\n",
    "                    path=image_path,\n",
    "                    width=width, height=height,\n",
    "                    polygons=polygons)\n",
    "\n",
    "                num_images_added += 1\n",
    "                print(colored(f\"Loading images {num_images_added}/{len(annotations)}\"), end='\\r')\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a monkey dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != MONKEY_CLASS_ID_STR:\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == MONKEY_CLASS_ID_STR:\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "\n",
    "Ensure the dataset is in the following form:\n",
    "\n",
    "dirName  \n",
    "└── train  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── a.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── b.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── c.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── via_region_data.json  \n",
    "└── val  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── c.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── d.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├── e.jpg  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└── via_regon_data.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_1718_00108006.jpg', 'IMG_1718_00108010.jpg', 'IMG_1718_00108017.jpg']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "path = (DATASET_DIR / \"images\" / \"*.*\")\n",
    "\n",
    "X = [os.path.basename(x) for x in glob.glob(str(path))]\n",
    "print(X[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_train_dataset(X_train_fold):\n",
    "    print(\"Preparing Dataset\")\n",
    "    # Annotated using: https://www.robots.ox.ac.uk/~vgg/software/via/\n",
    "    dataset = MonkeysDataset()\n",
    "    dataset.load_monkeys(DATASET_DIR, subset=X_train_fold)\n",
    "    dataset.prepare()\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_model(model_configuration):\n",
    "    print(\"Preparing training model...\")\n",
    "\n",
    "    # Create model in training mode\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=model_configuration,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def train_model(dataset_train, dataset_val, train_config, training_epochs, fine_tune_epochs):\n",
    "\n",
    "    model = prepare_train_model(train_config)\n",
    "\n",
    "    print(colored(\"*\"*30 + \"Training Model\" + \"*\"*30, 'green'))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\"*30, \" Training model head layers \", \"*\"*30)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Train the head branches\n",
    "    # Passing layers=\"heads\" freezes all layers except the head\n",
    "    # layers. You can also pass a regular expression to select\n",
    "    # which layers to train by name pattern.\n",
    "\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=train_config.LEARNING_RATE,\n",
    "                epochs=training_epochs,\n",
    "                layers='heads',\n",
    "                verbose=0)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\"*30, \" Fine tune all layers \", \"*\"*30)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Fine tune all layers\n",
    "    # Passing layers=\"all\" trains all layers. You can also\n",
    "    # pass a regular expression to select which layers to\n",
    "    # train by name pattern.\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=train_config.LEARNING_RATE / 10,  # TODO determine why this is / 10\n",
    "                epochs=training_epochs+fine_tune_epochs,\n",
    "                layers=\"all\",\n",
    "                verbose=0)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_model(inference_config):\n",
    "    print(\"Getting inference model\")\n",
    "    # Recreate the model in inference mode\n",
    "    model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                              config=inference_config,\n",
    "                              model_dir=MODEL_DIR)\n",
    "\n",
    "    # Get path to saved weights\n",
    "    # Either set a specific path or find last trained weights\n",
    "    # model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "    model_path = model.find_last()\n",
    "\n",
    "    # Load trained weights\n",
    "    print(\"Loading weights from \", model_path)\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(dataset_val, inference_config):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\"*30, \" Evaluating model \", \"*\"*30)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Compute VOC-Style mAP @ IoU=0.5\n",
    "    # Running on 10 images. Increase for better accuracy.\n",
    "    # image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "\n",
    "    image_ids = dataset_val.image_ids\n",
    "\n",
    "    model = get_inference_model(inference_config)\n",
    "\n",
    "    APs = []\n",
    "    for i, image_id in enumerate(image_ids):\n",
    "        print(f\"Evaluating image {i}/{len(image_ids)}\", end='\\r')\n",
    "\n",
    "        # Load image and ground truth data\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "            modellib.load_image_gt(dataset_val, inference_config,\n",
    "                                   image_id, use_mini_mask=False)\n",
    "        # molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "        # Run object detection\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        # Compute AP\n",
    "        AP, precisions, recalls, overlaps =\\\n",
    "            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                             r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=IOU_THRESHOLD)\n",
    "        APs.append(AP)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Finished evaluating\")\n",
    "    return np.mean(APs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def kfold_model(n_splits, X_train, model_config, inference_config, train_epochs, fine_tune_epochs):\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "\n",
    "    mAPs = []\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train = np.array(X_train)\n",
    "        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "\n",
    "        print(colored(\"*\"*30 + f\" Beginning fold {count} \" + \"*\"*30, 'green'))\n",
    "        count += 1\n",
    "\n",
    "        # Split our training data further into a train and validation set that will be used during *Training*\n",
    "        X_train_train_sub, X_train_val_sub = train_test_split(X_train_fold, test_size=0.1, random_state=SEED)\n",
    "\n",
    "        # Train and validation sets used during model training\n",
    "        dataset_train = prepare_model_train_dataset(X_train_train_sub)\n",
    "        dataset_val = prepare_model_train_dataset(X_train_val_sub)\n",
    "\n",
    "        # Test set used to evaluate model performance *Testing*\n",
    "        dataset_test = prepare_model_train_dataset(X_test_fold)\n",
    "\n",
    "        train_model(dataset_train, dataset_val, model_config, train_epochs, fine_tune_epochs)\n",
    "\n",
    "        # Mean Average Precision for the trained model\n",
    "        mAP = evaluate_model(dataset_test, inference_config)\n",
    "\n",
    "        mAPs.append(mAP)\n",
    "\n",
    "        print(f\"Result for fold is : {mAP}\")\n",
    "\n",
    "    # Averaged mAP accross the k folds\n",
    "    averaged_mAPs = np.mean(mAPs)\n",
    "    print(colored(f\"mAP: {averaged_mAPs}\"))\n",
    "\n",
    "    return averaged_mAPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 192\n",
      "Reservered X_val length: 48\n"
     ]
    }
   ],
   "source": [
    "SEED = 123\n",
    "\n",
    "X_train, X_val = train_test_split(X, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"X_train length: {len(X_train)}\")\n",
    "print(f\"Reservered X_val length: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num permutations: 3\n",
      "Permutations:  [0.01, 0.001, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "learning_rate_search_space = [0.01, 0.001, 0.0001]\n",
    "\n",
    "num_hyperparameters = 1\n",
    "\n",
    "search_permutations = learning_rate_search_space\n",
    "\n",
    "results = np.zeros((len(learning_rate_search_space), num_hyperparameters + 1))\n",
    "\n",
    "print(f'num permutations: {len(search_permutations)}')\n",
    "print(\"Permutations: \", search_permutations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_config(learning_rate, i, results, X_train, train_epochs=1, fine_tune_epochs=1, num_folds=2):\n",
    "\n",
    "    print(colored(\"*\"*30 + f\" Evaluating variation {i+1} \" + \"*\"*30, \"green\"))\n",
    "\n",
    "    # Model configurations, with hyperparameters\n",
    "    train_config, inference_config = get_config(learning_rate, len(X_train))\n",
    "\n",
    "    averaged_mAPs = kfold_model(num_folds, X_train, train_config, inference_config, train_epochs, fine_tune_epochs)\n",
    "\n",
    "    print(f\"RESULT for lr: {learning_rate} is mAP of {averaged_mAPs}\")\n",
    "\n",
    "    results[i, :] = learning_rate, averaged_mAPs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS\n",
    "\n",
    "Run the following one by one. If the kernel dies, rerun it all from the top to here, and then _ONLY_ the cell that died below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m****************************** Evaluating variation 1 ******************************\u001b[0m\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        1\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           monkeys\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                24\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\u001b[32m****************************** Beginning fold 1 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.01\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1625\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 97s 4s/step - loss: 1.8903 - rpn_class_loss: 0.0195 - rpn_bbox_loss: 0.6450 - mrcnn_class_loss: 0.1169 - mrcnn_bbox_loss: 0.6825 - mrcnn_mask_loss: 0.4264 - val_loss: 1.0633 - val_rpn_class_loss: 0.0090 - val_rpn_bbox_loss: 0.5014 - val_mrcnn_class_loss: 0.0256 - val_mrcnn_bbox_loss: 0.3179 - val_mrcnn_mask_loss: 0.2095\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 84s 4s/step - loss: 0.9573 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.4620 - mrcnn_class_loss: 0.0375 - mrcnn_bbox_loss: 0.2915 - mrcnn_mask_loss: 0.1586 - val_loss: 0.9203 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.5286 - val_mrcnn_class_loss: 0.0353 - val_mrcnn_bbox_loss: 0.1897 - val_mrcnn_mask_loss: 0.1607\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 85s 4s/step - loss: 0.8803 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.5115 - mrcnn_class_loss: 0.0242 - mrcnn_bbox_loss: 0.2063 - mrcnn_mask_loss: 0.1324 - val_loss: 0.8036 - val_rpn_class_loss: 0.0052 - val_rpn_bbox_loss: 0.4433 - val_mrcnn_class_loss: 0.0230 - val_mrcnn_bbox_loss: 0.2017 - val_mrcnn_mask_loss: 0.1304\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 85s 4s/step - loss: 0.5884 - rpn_class_loss: 0.0056 - rpn_bbox_loss: 0.3235 - mrcnn_class_loss: 0.0255 - mrcnn_bbox_loss: 0.1269 - mrcnn_mask_loss: 0.1069 - val_loss: 0.6697 - val_rpn_class_loss: 0.0087 - val_rpn_bbox_loss: 0.3850 - val_mrcnn_class_loss: 0.0216 - val_mrcnn_bbox_loss: 0.1308 - val_mrcnn_mask_loss: 0.1237\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 86s 4s/step - loss: 0.5369 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.3154 - mrcnn_class_loss: 0.0170 - mrcnn_bbox_loss: 0.1005 - mrcnn_mask_loss: 0.0977 - val_loss: 0.8214 - val_rpn_class_loss: 0.0068 - val_rpn_bbox_loss: 0.5991 - val_mrcnn_class_loss: 0.0143 - val_mrcnn_bbox_loss: 0.0822 - val_mrcnn_mask_loss: 0.1189\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1625\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 129s 5s/step - loss: 0.3839 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.2138 - mrcnn_class_loss: 0.0180 - mrcnn_bbox_loss: 0.0574 - mrcnn_mask_loss: 0.0895 - val_loss: 0.6576 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.4120 - val_mrcnn_class_loss: 0.0538 - val_mrcnn_bbox_loss: 0.0662 - val_mrcnn_mask_loss: 0.1175\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.2967 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.1370 - mrcnn_class_loss: 0.0212 - mrcnn_bbox_loss: 0.0451 - mrcnn_mask_loss: 0.0881 - val_loss: 0.4265 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2611 - val_mrcnn_class_loss: 0.0111 - val_mrcnn_bbox_loss: 0.0527 - val_mrcnn_mask_loss: 0.0951\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 101s 4s/step - loss: 0.1957 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.0691 - mrcnn_class_loss: 0.0097 - mrcnn_bbox_loss: 0.0315 - mrcnn_mask_loss: 0.0808 - val_loss: 0.4157 - val_rpn_class_loss: 0.0058 - val_rpn_bbox_loss: 0.2513 - val_mrcnn_class_loss: 0.0124 - val_mrcnn_bbox_loss: 0.0480 - val_mrcnn_mask_loss: 0.0983\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.1640 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.0491 - mrcnn_class_loss: 0.0082 - mrcnn_bbox_loss: 0.0256 - mrcnn_mask_loss: 0.0764 - val_loss: 0.4042 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.2285 - val_mrcnn_class_loss: 0.0100 - val_mrcnn_bbox_loss: 0.0601 - val_mrcnn_mask_loss: 0.0992\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.1719 - rpn_class_loss: 0.0048 - rpn_bbox_loss: 0.0496 - mrcnn_class_loss: 0.0138 - mrcnn_bbox_loss: 0.0259 - mrcnn_mask_loss: 0.0778 - val_loss: 0.4045 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.2389 - val_mrcnn_class_loss: 0.0144 - val_mrcnn_bbox_loss: 0.0453 - val_mrcnn_mask_loss: 0.1009\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1625\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.53125\n",
      "\u001b[32m****************************** Beginning fold 2 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.01\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1643\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 113s 5s/step - loss: 1.5615 - rpn_class_loss: 0.0198 - rpn_bbox_loss: 0.5820 - mrcnn_class_loss: 0.0939 - mrcnn_bbox_loss: 0.5677 - mrcnn_mask_loss: 0.2981 - val_loss: 1.0768 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.4645 - val_mrcnn_class_loss: 0.0553 - val_mrcnn_bbox_loss: 0.3514 - val_mrcnn_mask_loss: 0.1996\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.9375 - rpn_class_loss: 0.0053 - rpn_bbox_loss: 0.4455 - mrcnn_class_loss: 0.0284 - mrcnn_bbox_loss: 0.2981 - mrcnn_mask_loss: 0.1602 - val_loss: 0.8426 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.4000 - val_mrcnn_class_loss: 0.0339 - val_mrcnn_bbox_loss: 0.2335 - val_mrcnn_mask_loss: 0.1709\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 109s 5s/step - loss: 0.6762 - rpn_class_loss: 0.0056 - rpn_bbox_loss: 0.3508 - mrcnn_class_loss: 0.0333 - mrcnn_bbox_loss: 0.1653 - mrcnn_mask_loss: 0.1212 - val_loss: 0.7291 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.4330 - val_mrcnn_class_loss: 0.0275 - val_mrcnn_bbox_loss: 0.1286 - val_mrcnn_mask_loss: 0.1359\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 109s 5s/step - loss: 0.6204 - rpn_class_loss: 0.0051 - rpn_bbox_loss: 0.3728 - mrcnn_class_loss: 0.0177 - mrcnn_bbox_loss: 0.1188 - mrcnn_mask_loss: 0.1061 - val_loss: 0.8964 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.5772 - val_mrcnn_class_loss: 0.0324 - val_mrcnn_bbox_loss: 0.1554 - val_mrcnn_mask_loss: 0.1276\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 110s 5s/step - loss: 0.5375 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.2951 - mrcnn_class_loss: 0.0210 - mrcnn_bbox_loss: 0.1073 - mrcnn_mask_loss: 0.1089 - val_loss: 0.5858 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.3397 - val_mrcnn_class_loss: 0.0292 - val_mrcnn_bbox_loss: 0.0931 - val_mrcnn_mask_loss: 0.1192\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1643\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 148s 6s/step - loss: 0.3733 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.2042 - mrcnn_class_loss: 0.0164 - mrcnn_bbox_loss: 0.0544 - mrcnn_mask_loss: 0.0938 - val_loss: 0.3709 - val_rpn_class_loss: 0.0035 - val_rpn_bbox_loss: 0.1485 - val_mrcnn_class_loss: 0.0276 - val_mrcnn_bbox_loss: 0.0681 - val_mrcnn_mask_loss: 0.1232\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 118s 5s/step - loss: 0.2320 - rpn_class_loss: 0.0040 - rpn_bbox_loss: 0.0895 - mrcnn_class_loss: 0.0177 - mrcnn_bbox_loss: 0.0361 - mrcnn_mask_loss: 0.0846 - val_loss: 0.3551 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.1407 - val_mrcnn_class_loss: 0.0260 - val_mrcnn_bbox_loss: 0.0731 - val_mrcnn_mask_loss: 0.1122\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.2006 - rpn_class_loss: 0.0037 - rpn_bbox_loss: 0.0723 - mrcnn_class_loss: 0.0141 - mrcnn_bbox_loss: 0.0305 - mrcnn_mask_loss: 0.0801 - val_loss: 0.3923 - val_rpn_class_loss: 0.0029 - val_rpn_bbox_loss: 0.1626 - val_mrcnn_class_loss: 0.0206 - val_mrcnn_bbox_loss: 0.0739 - val_mrcnn_mask_loss: 0.1323\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 120s 5s/step - loss: 0.1594 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0453 - mrcnn_class_loss: 0.0092 - mrcnn_bbox_loss: 0.0244 - mrcnn_mask_loss: 0.0771 - val_loss: 0.3439 - val_rpn_class_loss: 0.0028 - val_rpn_bbox_loss: 0.1274 - val_mrcnn_class_loss: 0.0193 - val_mrcnn_bbox_loss: 0.0729 - val_mrcnn_mask_loss: 0.1215\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 121s 5s/step - loss: 0.1391 - rpn_class_loss: 0.0031 - rpn_bbox_loss: 0.0296 - mrcnn_class_loss: 0.0114 - mrcnn_bbox_loss: 0.0209 - mrcnn_mask_loss: 0.0741 - val_loss: 0.3360 - val_rpn_class_loss: 0.0026 - val_rpn_bbox_loss: 0.1094 - val_mrcnn_class_loss: 0.0148 - val_mrcnn_bbox_loss: 0.0714 - val_mrcnn_mask_loss: 0.1378\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1643\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.65625\n",
      "\u001b[32m****************************** Beginning fold 3 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.01\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1709\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 132s 5s/step - loss: 2.0282 - rpn_class_loss: 0.0216 - rpn_bbox_loss: 0.6116 - mrcnn_class_loss: 0.0967 - mrcnn_bbox_loss: 0.6282 - mrcnn_mask_loss: 0.6701 - val_loss: 1.2651 - val_rpn_class_loss: 0.0082 - val_rpn_bbox_loss: 0.5276 - val_mrcnn_class_loss: 0.0212 - val_mrcnn_bbox_loss: 0.3162 - val_mrcnn_mask_loss: 0.3920\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 122s 5s/step - loss: 0.9347 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.3733 - mrcnn_class_loss: 0.0321 - mrcnn_bbox_loss: 0.2639 - mrcnn_mask_loss: 0.2597 - val_loss: 0.9775 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.3817 - val_mrcnn_class_loss: 0.0976 - val_mrcnn_bbox_loss: 0.3078 - val_mrcnn_mask_loss: 0.1824\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 119s 5s/step - loss: 0.7029 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.3509 - mrcnn_class_loss: 0.0364 - mrcnn_bbox_loss: 0.1608 - mrcnn_mask_loss: 0.1496 - val_loss: 0.6590 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.3128 - val_mrcnn_class_loss: 0.0220 - val_mrcnn_bbox_loss: 0.1692 - val_mrcnn_mask_loss: 0.1506\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 125s 5s/step - loss: 0.6075 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.2778 - mrcnn_class_loss: 0.0275 - mrcnn_bbox_loss: 0.1599 - mrcnn_mask_loss: 0.1380 - val_loss: 0.7329 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.4346 - val_mrcnn_class_loss: 0.0313 - val_mrcnn_bbox_loss: 0.1240 - val_mrcnn_mask_loss: 0.1374\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 122s 5s/step - loss: 0.4982 - rpn_class_loss: 0.0039 - rpn_bbox_loss: 0.2826 - mrcnn_class_loss: 0.0231 - mrcnn_bbox_loss: 0.0840 - mrcnn_mask_loss: 0.1046 - val_loss: 0.6337 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.3820 - val_mrcnn_class_loss: 0.0218 - val_mrcnn_bbox_loss: 0.0947 - val_mrcnn_mask_loss: 0.1305\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1709\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 181s 8s/step - loss: 0.3359 - rpn_class_loss: 0.0042 - rpn_bbox_loss: 0.1659 - mrcnn_class_loss: 0.0177 - mrcnn_bbox_loss: 0.0534 - mrcnn_mask_loss: 0.0946 - val_loss: 0.5073 - val_rpn_class_loss: 0.0043 - val_rpn_bbox_loss: 0.3007 - val_mrcnn_class_loss: 0.0136 - val_mrcnn_bbox_loss: 0.0653 - val_mrcnn_mask_loss: 0.1234\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 145s 6s/step - loss: 0.2508 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.1064 - mrcnn_class_loss: 0.0183 - mrcnn_bbox_loss: 0.0344 - mrcnn_mask_loss: 0.0883 - val_loss: 0.4636 - val_rpn_class_loss: 0.0048 - val_rpn_bbox_loss: 0.2631 - val_mrcnn_class_loss: 0.0173 - val_mrcnn_bbox_loss: 0.0558 - val_mrcnn_mask_loss: 0.1224\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 141s 6s/step - loss: 0.2019 - rpn_class_loss: 0.0036 - rpn_bbox_loss: 0.0606 - mrcnn_class_loss: 0.0192 - mrcnn_bbox_loss: 0.0328 - mrcnn_mask_loss: 0.0858 - val_loss: 0.4346 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.2311 - val_mrcnn_class_loss: 0.0153 - val_mrcnn_bbox_loss: 0.0526 - val_mrcnn_mask_loss: 0.1310\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 135s 6s/step - loss: 0.1658 - rpn_class_loss: 0.0032 - rpn_bbox_loss: 0.0416 - mrcnn_class_loss: 0.0152 - mrcnn_bbox_loss: 0.0251 - mrcnn_mask_loss: 0.0808 - val_loss: 0.3550 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.1677 - val_mrcnn_class_loss: 0.0116 - val_mrcnn_bbox_loss: 0.0446 - val_mrcnn_mask_loss: 0.1264\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 138s 6s/step - loss: 0.1475 - rpn_class_loss: 0.0033 - rpn_bbox_loss: 0.0371 - mrcnn_class_loss: 0.0094 - mrcnn_bbox_loss: 0.0206 - mrcnn_mask_loss: 0.0772 - val_loss: 0.3715 - val_rpn_class_loss: 0.0044 - val_rpn_bbox_loss: 0.1802 - val_mrcnn_class_loss: 0.0126 - val_mrcnn_bbox_loss: 0.0512 - val_mrcnn_mask_loss: 0.1230\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211021T1709\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.515625\n",
      "mAP: 0.5677083333333334\u001b[0m\n",
      "RESULT for lr: 0.01 is mAP of 0.5677083333333334\n"
     ]
    }
   ],
   "source": [
    "# value = 0\n",
    "# test_one_config(search_permutations[value], value, results, X_train, train_epochs=num_train_epochs, fine_tune_epochs=num_fine_tune_epochs, num_folds=num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m****************************** Evaluating variation 2 ******************************\u001b[0m\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        1\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           monkeys\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                24\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "\u001b[32m****************************** Beginning fold 1 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0923\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 99s 4s/step - loss: 2.3422 - rpn_class_loss: 0.0355 - rpn_bbox_loss: 0.7052 - mrcnn_class_loss: 0.2799 - mrcnn_bbox_loss: 0.6512 - mrcnn_mask_loss: 0.6704 - val_loss: 1.3978 - val_rpn_class_loss: 0.0250 - val_rpn_bbox_loss: 0.6109 - val_mrcnn_class_loss: 0.0277 - val_mrcnn_bbox_loss: 0.3348 - val_mrcnn_mask_loss: 0.3994\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 88s 4s/step - loss: 1.0944 - rpn_class_loss: 0.0203 - rpn_bbox_loss: 0.4718 - mrcnn_class_loss: 0.0484 - mrcnn_bbox_loss: 0.2534 - mrcnn_mask_loss: 0.3006 - val_loss: 0.9660 - val_rpn_class_loss: 0.0146 - val_rpn_bbox_loss: 0.4900 - val_mrcnn_class_loss: 0.0206 - val_mrcnn_bbox_loss: 0.2309 - val_mrcnn_mask_loss: 0.2098\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 85s 4s/step - loss: 0.8209 - rpn_class_loss: 0.0137 - rpn_bbox_loss: 0.4123 - mrcnn_class_loss: 0.0273 - mrcnn_bbox_loss: 0.1656 - mrcnn_mask_loss: 0.2021 - val_loss: 0.8062 - val_rpn_class_loss: 0.0102 - val_rpn_bbox_loss: 0.4364 - val_mrcnn_class_loss: 0.0252 - val_mrcnn_bbox_loss: 0.1590 - val_mrcnn_mask_loss: 0.1754\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 84s 3s/step - loss: 0.6349 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.3306 - mrcnn_class_loss: 0.0234 - mrcnn_bbox_loss: 0.1101 - mrcnn_mask_loss: 0.1616 - val_loss: 0.7384 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.3864 - val_mrcnn_class_loss: 0.0252 - val_mrcnn_bbox_loss: 0.1650 - val_mrcnn_mask_loss: 0.1543\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 84s 3s/step - loss: 0.5861 - rpn_class_loss: 0.0075 - rpn_bbox_loss: 0.3086 - mrcnn_class_loss: 0.0196 - mrcnn_bbox_loss: 0.0999 - mrcnn_mask_loss: 0.1505 - val_loss: 0.6923 - val_rpn_class_loss: 0.0064 - val_rpn_bbox_loss: 0.3730 - val_mrcnn_class_loss: 0.0229 - val_mrcnn_bbox_loss: 0.1295 - val_mrcnn_mask_loss: 0.1605\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.0001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0923\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 139s 6s/step - loss: 0.4754 - rpn_class_loss: 0.0068 - rpn_bbox_loss: 0.2468 - mrcnn_class_loss: 0.0221 - mrcnn_bbox_loss: 0.0643 - mrcnn_mask_loss: 0.1353 - val_loss: 0.6343 - val_rpn_class_loss: 0.0066 - val_rpn_bbox_loss: 0.3444 - val_mrcnn_class_loss: 0.0204 - val_mrcnn_bbox_loss: 0.1165 - val_mrcnn_mask_loss: 0.1464\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 105s 4s/step - loss: 0.4301 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.2260 - mrcnn_class_loss: 0.0198 - mrcnn_bbox_loss: 0.0522 - mrcnn_mask_loss: 0.1259 - val_loss: 0.6160 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.3404 - val_mrcnn_class_loss: 0.0180 - val_mrcnn_bbox_loss: 0.1050 - val_mrcnn_mask_loss: 0.1465\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.3815 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.1879 - mrcnn_class_loss: 0.0142 - mrcnn_bbox_loss: 0.0489 - mrcnn_mask_loss: 0.1243 - val_loss: 0.6019 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.3305 - val_mrcnn_class_loss: 0.0167 - val_mrcnn_bbox_loss: 0.1022 - val_mrcnn_mask_loss: 0.1463\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.3509 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.1656 - mrcnn_class_loss: 0.0149 - mrcnn_bbox_loss: 0.0451 - mrcnn_mask_loss: 0.1192 - val_loss: 0.5937 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.3236 - val_mrcnn_class_loss: 0.0173 - val_mrcnn_bbox_loss: 0.1013 - val_mrcnn_mask_loss: 0.1458\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 97s 4s/step - loss: 0.3455 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.1612 - mrcnn_class_loss: 0.0206 - mrcnn_bbox_loss: 0.0406 - mrcnn_mask_loss: 0.1168 - val_loss: 0.5911 - val_rpn_class_loss: 0.0060 - val_rpn_bbox_loss: 0.3139 - val_mrcnn_class_loss: 0.0194 - val_mrcnn_bbox_loss: 0.1058 - val_mrcnn_mask_loss: 0.1461\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0923\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.328125\n",
      "\u001b[32m****************************** Beginning fold 2 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0941\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 113s 5s/step - loss: 2.1443 - rpn_class_loss: 0.0338 - rpn_bbox_loss: 0.7035 - mrcnn_class_loss: 0.1810 - mrcnn_bbox_loss: 0.5350 - mrcnn_mask_loss: 0.6910 - val_loss: 1.2994 - val_rpn_class_loss: 0.0229 - val_rpn_bbox_loss: 0.5097 - val_mrcnn_class_loss: 0.0469 - val_mrcnn_bbox_loss: 0.2885 - val_mrcnn_mask_loss: 0.4315\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 109s 5s/step - loss: 1.0319 - rpn_class_loss: 0.0220 - rpn_bbox_loss: 0.4443 - mrcnn_class_loss: 0.0357 - mrcnn_bbox_loss: 0.2059 - mrcnn_mask_loss: 0.3240 - val_loss: 0.9727 - val_rpn_class_loss: 0.0119 - val_rpn_bbox_loss: 0.4197 - val_mrcnn_class_loss: 0.0387 - val_mrcnn_bbox_loss: 0.2194 - val_mrcnn_mask_loss: 0.2829\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 111s 5s/step - loss: 0.7482 - rpn_class_loss: 0.0119 - rpn_bbox_loss: 0.3407 - mrcnn_class_loss: 0.0282 - mrcnn_bbox_loss: 0.1579 - mrcnn_mask_loss: 0.2096 - val_loss: 0.8618 - val_rpn_class_loss: 0.0086 - val_rpn_bbox_loss: 0.3908 - val_mrcnn_class_loss: 0.0322 - val_mrcnn_bbox_loss: 0.1825 - val_mrcnn_mask_loss: 0.2477\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.6108 - rpn_class_loss: 0.0092 - rpn_bbox_loss: 0.2999 - mrcnn_class_loss: 0.0232 - mrcnn_bbox_loss: 0.1039 - mrcnn_mask_loss: 0.1746 - val_loss: 0.7724 - val_rpn_class_loss: 0.0051 - val_rpn_bbox_loss: 0.3660 - val_mrcnn_class_loss: 0.0514 - val_mrcnn_bbox_loss: 0.1430 - val_mrcnn_mask_loss: 0.2070\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 107s 4s/step - loss: 0.5593 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.2705 - mrcnn_class_loss: 0.0273 - mrcnn_bbox_loss: 0.0959 - mrcnn_mask_loss: 0.1592 - val_loss: 0.7333 - val_rpn_class_loss: 0.0047 - val_rpn_bbox_loss: 0.3299 - val_mrcnn_class_loss: 0.0401 - val_mrcnn_bbox_loss: 0.1855 - val_mrcnn_mask_loss: 0.1732\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.0001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0941\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 153s 6s/step - loss: 0.4380 - rpn_class_loss: 0.0062 - rpn_bbox_loss: 0.1996 - mrcnn_class_loss: 0.0233 - mrcnn_bbox_loss: 0.0658 - mrcnn_mask_loss: 0.1431 - val_loss: 0.6566 - val_rpn_class_loss: 0.0045 - val_rpn_bbox_loss: 0.3048 - val_mrcnn_class_loss: 0.0434 - val_mrcnn_bbox_loss: 0.1202 - val_mrcnn_mask_loss: 0.1836\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 123s 5s/step - loss: 0.4217 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.2018 - mrcnn_class_loss: 0.0220 - mrcnn_bbox_loss: 0.0531 - mrcnn_mask_loss: 0.1389 - val_loss: 0.6341 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.2915 - val_mrcnn_class_loss: 0.0413 - val_mrcnn_bbox_loss: 0.1193 - val_mrcnn_mask_loss: 0.1774\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 117s 5s/step - loss: 0.3569 - rpn_class_loss: 0.0058 - rpn_bbox_loss: 0.1552 - mrcnn_class_loss: 0.0208 - mrcnn_bbox_loss: 0.0454 - mrcnn_mask_loss: 0.1296 - val_loss: 0.6461 - val_rpn_class_loss: 0.0042 - val_rpn_bbox_loss: 0.2888 - val_mrcnn_class_loss: 0.0378 - val_mrcnn_bbox_loss: 0.1309 - val_mrcnn_mask_loss: 0.1845\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 116s 5s/step - loss: 0.3369 - rpn_class_loss: 0.0058 - rpn_bbox_loss: 0.1424 - mrcnn_class_loss: 0.0200 - mrcnn_bbox_loss: 0.0416 - mrcnn_mask_loss: 0.1270 - val_loss: 0.6364 - val_rpn_class_loss: 0.0041 - val_rpn_bbox_loss: 0.2663 - val_mrcnn_class_loss: 0.0399 - val_mrcnn_bbox_loss: 0.1390 - val_mrcnn_mask_loss: 0.1872\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 124s 5s/step - loss: 0.3195 - rpn_class_loss: 0.0050 - rpn_bbox_loss: 0.1287 - mrcnn_class_loss: 0.0221 - mrcnn_bbox_loss: 0.0402 - mrcnn_mask_loss: 0.1235 - val_loss: 0.6158 - val_rpn_class_loss: 0.0038 - val_rpn_bbox_loss: 0.2636 - val_mrcnn_class_loss: 0.0372 - val_mrcnn_bbox_loss: 0.1277 - val_mrcnn_mask_loss: 0.1835\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T0941\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.25\n",
      "\u001b[32m****************************** Beginning fold 3 ******************************\u001b[0m\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing Dataset\n",
      "Preparing training model...\n",
      "\u001b[32m******************************Training Model******************************\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "******************************  Training model head layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T1007\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 130s 5s/step - loss: 2.7799 - rpn_class_loss: 0.0350 - rpn_bbox_loss: 0.6755 - mrcnn_class_loss: 0.5944 - mrcnn_bbox_loss: 0.5532 - mrcnn_mask_loss: 0.9218 - val_loss: 1.5318 - val_rpn_class_loss: 0.0263 - val_rpn_bbox_loss: 0.5345 - val_mrcnn_class_loss: 0.0410 - val_mrcnn_bbox_loss: 0.3105 - val_mrcnn_mask_loss: 0.6195\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 122s 5s/step - loss: 1.3797 - rpn_class_loss: 0.0214 - rpn_bbox_loss: 0.4752 - mrcnn_class_loss: 0.0410 - mrcnn_bbox_loss: 0.2433 - mrcnn_mask_loss: 0.5988 - val_loss: 1.3754 - val_rpn_class_loss: 0.0156 - val_rpn_bbox_loss: 0.5305 - val_mrcnn_class_loss: 0.0217 - val_mrcnn_bbox_loss: 0.2364 - val_mrcnn_mask_loss: 0.5712\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 119s 5s/step - loss: 1.1224 - rpn_class_loss: 0.0136 - rpn_bbox_loss: 0.3812 - mrcnn_class_loss: 0.0345 - mrcnn_bbox_loss: 0.1594 - mrcnn_mask_loss: 0.5338 - val_loss: 1.1619 - val_rpn_class_loss: 0.0116 - val_rpn_bbox_loss: 0.3904 - val_mrcnn_class_loss: 0.0195 - val_mrcnn_bbox_loss: 0.2387 - val_mrcnn_mask_loss: 0.5017\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 121s 5s/step - loss: 0.8954 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.3279 - mrcnn_class_loss: 0.0226 - mrcnn_bbox_loss: 0.1278 - mrcnn_mask_loss: 0.4075 - val_loss: 0.8214 - val_rpn_class_loss: 0.0098 - val_rpn_bbox_loss: 0.3919 - val_mrcnn_class_loss: 0.0201 - val_mrcnn_bbox_loss: 0.1379 - val_mrcnn_mask_loss: 0.2618\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 127s 5s/step - loss: 0.6585 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.2874 - mrcnn_class_loss: 0.0271 - mrcnn_bbox_loss: 0.1021 - mrcnn_mask_loss: 0.2341 - val_loss: 0.7374 - val_rpn_class_loss: 0.0082 - val_rpn_bbox_loss: 0.3796 - val_mrcnn_class_loss: 0.0198 - val_mrcnn_bbox_loss: 0.1143 - val_mrcnn_mask_loss: 0.2154\n",
      "\n",
      "\n",
      "\n",
      "******************************  Fine tune all layers  ******************************\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting at epoch 5. LR=0.0001\n",
      "\n",
      "Checkpoint Path: e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T1007\\mask_rcnn_monkeys_{epoch:04d}.h5\n",
      "In model:  rpn_model\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 183s 8s/step - loss: 0.5207 - rpn_class_loss: 0.0074 - rpn_bbox_loss: 0.2392 - mrcnn_class_loss: 0.0239 - mrcnn_bbox_loss: 0.0637 - mrcnn_mask_loss: 0.1865 - val_loss: 0.6676 - val_rpn_class_loss: 0.0088 - val_rpn_bbox_loss: 0.3359 - val_mrcnn_class_loss: 0.0264 - val_mrcnn_bbox_loss: 0.1067 - val_mrcnn_mask_loss: 0.1898\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 135s 6s/step - loss: 0.4627 - rpn_class_loss: 0.0078 - rpn_bbox_loss: 0.2017 - mrcnn_class_loss: 0.0237 - mrcnn_bbox_loss: 0.0543 - mrcnn_mask_loss: 0.1751 - val_loss: 0.6277 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.3118 - val_mrcnn_class_loss: 0.0216 - val_mrcnn_bbox_loss: 0.1020 - val_mrcnn_mask_loss: 0.1842\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 136s 6s/step - loss: 0.4136 - rpn_class_loss: 0.0073 - rpn_bbox_loss: 0.1800 - mrcnn_class_loss: 0.0179 - mrcnn_bbox_loss: 0.0464 - mrcnn_mask_loss: 0.1621 - val_loss: 0.6104 - val_rpn_class_loss: 0.0080 - val_rpn_bbox_loss: 0.2957 - val_mrcnn_class_loss: 0.0235 - val_mrcnn_bbox_loss: 0.1078 - val_mrcnn_mask_loss: 0.1754\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 139s 6s/step - loss: 0.3893 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.1623 - mrcnn_class_loss: 0.0217 - mrcnn_bbox_loss: 0.0435 - mrcnn_mask_loss: 0.1547 - val_loss: 0.5915 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.2902 - val_mrcnn_class_loss: 0.0187 - val_mrcnn_bbox_loss: 0.1085 - val_mrcnn_mask_loss: 0.1665\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 138s 6s/step - loss: 0.3547 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.1398 - mrcnn_class_loss: 0.0170 - mrcnn_bbox_loss: 0.0425 - mrcnn_mask_loss: 0.1488 - val_loss: 0.5570 - val_rpn_class_loss: 0.0077 - val_rpn_bbox_loss: 0.2671 - val_mrcnn_class_loss: 0.0215 - val_mrcnn_bbox_loss: 0.0991 - val_mrcnn_mask_loss: 0.1617\n",
      "\n",
      "\n",
      "\n",
      "******************************  Evaluating model  ******************************\n",
      "\n",
      "\n",
      "\n",
      "Getting inference model\n",
      "Loading weights from  e:\\Uni\\CompSci 760\\AucklandZooSquirrelMonkeyCOCO\\Mask_RCNN\\logs\\monkeys20211022T1007\\mask_rcnn_monkeys_0010.h5\n",
      "Re-starting from epoch 10\n",
      "Finished evaluating\n",
      "Result for fold is : 0.109375\n",
      "mAP: 0.22916666666666666\u001b[0m\n",
      "RESULT for lr: 0.001 is mAP of 0.22916666666666666\n"
     ]
    }
   ],
   "source": [
    "value = 1\n",
    "test_one_config(search_permutations[value], value, results, X_train, train_epochs=num_train_epochs, fine_tune_epochs=num_fine_tune_epochs, num_folds=num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 2\n",
    "test_one_config(search_permutations[value], value, results, X_train, train_epochs=num_train_epochs, fine_tune_epochs=num_fine_tune_epochs, num_folds=num_folds)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7643b6ca01263e07ff32623fdc69e42a4e339236c5f6bad1bd062f88f226e188"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('MaskRCNN': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
